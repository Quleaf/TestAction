name: ci
# Version 1.0.0
# This workflow is triggered on push events to the repository
# Please find readme.md for the usage of this workflow

on:
  push:
      branches:
        - 'cicd*'
jobs:
  PREPARE-job:
    runs-on: [self-hosted, Linux, X64, podman, test, setonix-podman02]
    outputs:
      # Job Output Variables:
      # - proceed_valid: Whether to proceed with build (true/false, e.g., "true")
      # - dockerfile_path: Path to the modified Dockerfile (e.g., "x86/ex1.dockerfile")
      # - version: Semver version from Dockerfile (e.g., "0.0.5")
      # - devmode: Development mode flag (true/false, e.g., "true")
      # - noscan: Skip security scan flag (true/false, e.g., "false")
      # - files: List of changed files for debugging (e.g., "x86/ex1.dockerfile")
      proceed_valid: ${{ steps.set_proceed_flag.outputs.proceed_valid }}
      dockerfile_path: ${{ steps.set_proceed_flag.outputs.dockerfile_path }}
      version: ${{ steps.set_proceed_flag.outputs.version }}
      devmode: ${{ steps.set_proceed_flag.outputs.devmode }}
      noscan: ${{ steps.set_proceed_flag.outputs.noscan }}
      files: ${{ steps.changed_files.outputs.files }}
      date: ${{ steps.date.outputs.date }}
    
    steps:
      - name: Set default runner label
        id: set_default_runner_label
        run: |
          echo "runner_label=ubuntu-latest" >> $GITHUB_OUTPUT

      # - name: Check required variables and secrets and set runner-default
      #   id: check_vars_secrets
      #   run: |
      #     missing_vars=()
      #     missing_secrets=()

      #     # check Variables
      #     if [ -z "${{ vars.DOCKERHUB_USERNAME }}" ]; then
      #       missing_vars+=("DOCKERHUB_USERNAME")
      #     fi

      #     if [ -z "${{ vars.QUAYIO_USERNAME }}" ]; then
      #       missing_vars+=("QUAYIO_USERNAME")
      #     fi

      #     if [ -z "${{ vars.ACACIA_BUCKETNAME }}" ]; then
      #       missing_vars+=("ACACIA_BUCKETNAME")
      #     fi

      #     # check Secrets
      #     if [ -z "${{ secrets.PAT_TOKEN }}" ]; then
      #       missing_secrets+=("PAT_TOKEN")
      #     fi

      #     if [ -z "${{ secrets.DOCKERHUB_TOKEN }}" ]; then
      #       missing_secrets+=("DOCKERHUB_TOKEN")
      #     fi

      #     if [ -z "${{ secrets.QUAYIO_TOKEN }}" ]; then
      #       missing_secrets+=("QUAYIO_TOKEN")
      #     fi

      #     if [ -z "${{ secrets.ACACIA_ACCESS_KEY_ID }}" ]; then
      #       missing_secrets+=("ACACIA_ACCESS_KEY_ID")
      #     fi

      #     if [ -z "${{ secrets.ACACIA_SECRET_ACCESS_KEY }}" ]; then
      #       missing_secrets+=("ACACIA_SECRET_ACCESS_KEY")
      #     fi

      #     # If any missing variables or secrets, exit with error
      #     if [ ${#missing_vars[@]} -ne 0 ] || [ ${#missing_secrets[@]} -ne 0 ]; then
      #       echo "Some required variables or secrets are not set:"
      #       if [ ${#missing_vars[@]} -ne 0 ]; then
      #         echo "Missing Variables: ${missing_vars[@]}"
      #       fi
      #       if [ ${#missing_secrets[@]} -ne 0 ]; then
      #         echo "Missing Secrets: ${missing_secrets[@]}"
      #       fi
      #       exit 1
      #     else
      #       echo "All required variables and secrets are set."
      #     fi

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Ensure enough history is available

      - name: Verify git history depth
        run: |
          # Check if we have enough history for git diff
          if [ -z "${{ github.event.before }}" ]; then
            echo "Error: github.event.before is empty. Cannot perform git diff operation."
            echo "This usually means the repository history is not available or fetch-depth is insufficient."
            exit 1
          fi
          
          # Verify that we can access the previous commit
          if ! git rev-parse --verify ${{ github.event.before }} >/dev/null 2>&1; then
            echo "Error: Cannot access previous commit ${{ github.event.before }}"
            echo "This indicates that fetch-depth: 2 is not sufficient or the history is not available."
            exit 1
          fi
          
          echo "Git history verification passed. Previous commit ${{ github.event.before }} is accessible."

      - name: Get changed files
        id: changed_files
        run: |
          # Get all Dockerfile variants (case-insensitive)
          files=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep -i '\.dockerfile$' || true)
          
          if [ -z "$files" ]; then
            echo "No Dockerfile changes detected. This workflow only processes Dockerfile modifications."
            echo "files=" >> $GITHUB_OUTPUT
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Count the number of changed files
          file_count=$(echo "$files" | wc -l)
          if [ "$file_count" -gt 1 ]; then
            echo "Multiple Dockerfiles changed ($file_count files). This workflow only processes single file changes."
            echo "files<<EOF" >> $GITHUB_OUTPUT
            echo "$files" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Single Dockerfile changed: $files"
          echo "files<<EOF" >> $GITHUB_OUTPUT
          echo "$files" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "proceed_valid=true" >> $GITHUB_OUTPUT


      - name: Debug output of changed files 
        run: |
          echo "Files from output: ${{ steps.changed_files.outputs.files }}"      


      - name: Validate file changes
        id: validate_changes
        if: steps.changed_files.outputs.proceed_valid == 'true'
        run: |
          changed_files="${{ steps.changed_files.outputs.files }}"
          echo "Processing single file: $changed_files"
          echo "valid=true" >> $GITHUB_OUTPUT
          echo "dockerfile_path=$changed_files" >> $GITHUB_OUTPUT

      - name: Validate version label
        id: validate_version
        if: steps.validate_changes.outputs.valid == 'true'
        run: |
          file="${{ steps.validate_changes.outputs.dockerfile_path }}"
          
          if grep -q -E '^[^#]*LABEL\s+org\.opencontainers\.image\.version\s*=' "$file"; then
            version=$(grep -E '^[^#]*LABEL\s+org\.opencontainers\.image\.version\s*=' "$file" | sed -E 's/^[^#]*LABEL\s+org\.opencontainers\.image\.version\s*=\s*"?([^"]*)"?.*/\1/')
            
            if echo "$version" | grep -qE '^[0-9]+\.[0-9]+\.[0-9]+$'; then
              echo "Version: $version ✓"
              echo "valid=true" >> $GITHUB_OUTPUT
              echo "version=$version" >> $GITHUB_OUTPUT
            else
              echo "Version: $version ✗ (invalid semver)"
              echo "valid=false" >> $GITHUB_OUTPUT
              echo "message=Invalid version: $version" >> $GITHUB_OUTPUT
            fi
          else
            echo "Version: missing ✗"
            echo "valid=false" >> $GITHUB_OUTPUT
            echo "message=Missing version label" >> $GITHUB_OUTPUT
          fi

      - name: Parse optional settings
        id: parse_settings
        if: steps.validate_changes.outputs.valid == 'true'
        run: |
          file="${{ steps.validate_changes.outputs.dockerfile_path }}"
          
          # Dev mode
          if grep -q -E '^[^#]*LABEL\s+org\.opencontainers\.image\.devmode\s*=\s*true' "$file"; then
            echo "DevMode: enabled"
            echo "devmode=true" >> $GITHUB_OUTPUT
          else
            echo "DevMode: disabled"
            echo "devmode=false" >> $GITHUB_OUTPUT
          fi
          
          # Scan settings
          if grep -q -E '^[^#]*LABEL\s+org\.opencontainers\.image\.noscan\s*=\s*true' "$file"; then
            if grep -q -E '^[^#]*LABEL\s+org\.opencontainers\.image\.noscanreason\s*' "$file"; then 
              reason=$(grep -E '^[^#]*LABEL\s+org\.opencontainers\.image\.noscanreason\s*' "$file")
              echo "Scan: disabled ($reason)"
              echo "noscan=true" >> $GITHUB_OUTPUT
              echo "noscanreason=$reason" >> $GITHUB_OUTPUT
            else
              echo "Scan: disabled but no reason provided"
              echo "noscan=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "Scan: enabled"
            echo "noscan=false" >> $GITHUB_OUTPUT
          fi

      - name: Set proceed flag
        id: set_proceed_flag
        run: |
          files_proceed="${{ steps.changed_files.outputs.proceed_valid }}"
          changes_valid="${{ steps.validate_changes.outputs.valid }}"
          version_valid="${{ steps.validate_version.outputs.valid }}"
          
          # If files check failed, exit early
          if [ "$files_proceed" != "true" ]; then
            echo "(FAILED) File change validation failed"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
            echo "devmode=false" >> $GITHUB_OUTPUT
            echo "noscan=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Check version validation
          if [ "$version_valid" = "true" ]; then
            echo "(PASSED) All validations passed"
            echo "proceed_valid=true" >> $GITHUB_OUTPUT
          else
            echo "(FAILED) Version validation: ${{ steps.validate_version.outputs.message }}"
            echo "proceed_valid=false" >> $GITHUB_OUTPUT
          fi
          
          # Pass through outputs
          echo "dockerfile_path=${{ steps.validate_changes.outputs.dockerfile_path }}" >> $GITHUB_OUTPUT
          echo "version=${{ steps.validate_version.outputs.version }}" >> $GITHUB_OUTPUT
          echo "devmode=${{ steps.parse_settings.outputs.devmode || 'false' }}" >> $GITHUB_OUTPUT
          echo "noscan=${{ steps.parse_settings.outputs.noscan || 'false' }}" >> $GITHUB_OUTPUT 

      - name: Set current date
        if: steps.set_proceed_flag.outputs.proceed_valid == 'true'
        id: date
        run: |
          date_tag=$(date +'%m-%d')
          echo "Date tag: $date_tag"
          echo "date=$date_tag" >> $GITHUB_OUTPUT
      
  BUILD-job:
    needs: PREPARE-job
    runs-on: setonix-podman02
    if: needs.PREPARE-job.outputs.proceed_valid == 'true'
    steps:
      - name: Print hostname
        run: |
          echo "Hostname: $(hostname)"

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1  # As the runs-on machine maybe different from Build, re-checkout source code. Only the current commit is needed

      - name: Setup container environment
        id: setup_env
        run: |
          echo "Setting up container environment variables..."
          
          # Export environment variables
          export XDG_DATA_HOME=/container/${USER}/data
          export XDG_RUNTIME_DIR=/container/${USER}/runtime
          export TMPDIR=/container/${USER}/tmp/
          
          # Create required directories
          mkdir -p ${XDG_DATA_HOME}
          mkdir -p ${XDG_RUNTIME_DIR}
          mkdir -p ${TMPDIR}
          
          # Verify directories and output status
          echo "Environment setup completed:"
          echo "USER: ${USER}"
          echo "XDG_DATA_HOME: ${XDG_DATA_HOME}"
          echo "XDG_RUNTIME_DIR: ${XDG_RUNTIME_DIR}"
          echo "TMPDIR: ${TMPDIR}"
          
          # Check if directories exist
          for dir in "${XDG_DATA_HOME}" "${XDG_RUNTIME_DIR}" "${TMPDIR}"; do
            if [ -d "$dir" ]; then
              echo "✓ Podman Directory exists: $dir"
            else
              echo "✗ Podman Directory missing: $dir"
              exit 1
            fi
          done
          
          # Set environment variables for subsequent steps
          echo "XDG_DATA_HOME=${XDG_DATA_HOME}" >> $GITHUB_ENV
          echo "XDG_RUNTIME_DIR=${XDG_RUNTIME_DIR}" >> $GITHUB_ENV
          echo "TMPDIR=${TMPDIR}" >> $GITHUB_ENV

      - name: Build container with podman
        id: build_container
        run: |
          # Get variables from PREPARE-job
          dockerfile_path="${{ needs.PREPARE-job.outputs.dockerfile_path }}"
          version="${{ needs.PREPARE-job.outputs.version }}"
          
          # Extract filename without extension for tag
          dockerfile_name=$(basename "$dockerfile_path" .dockerfile)
          
          # Build with podman using docker format
          echo "Building container with podman..."
          echo "Dockerfile: $dockerfile_path"
          echo "Tag: ${dockerfile_name}:${version}"
          
          podman build --format=docker \
            -f "$dockerfile_path" \
            -t "${dockerfile_name}:${version}" \
            $(dirname "$dockerfile_path")
          
          # Verify the image was built
          if podman images | grep -q "${dockerfile_name}"; then
            echo "✓ Image built successfully: ${dockerfile_name}:${version}"
          else
            echo "✗ Failed to build image: ${dockerfile_name}:${version}"
            exit 1
          fi
          
          # Set outputs for next step
          # Output Variables:
          # - image_tag: Complete image tag with version (e.g., "ex1:0.0.5")
          # - dockerfile_name: Base name without extension (e.g., "ex1")
          echo "image_tag=${dockerfile_name}:${version}" >> $GITHUB_OUTPUT
          echo "dockerfile_name=${dockerfile_name}" >> $GITHUB_OUTPUT

      - name: Save container to archive
        id: save_container
        run: |
          # Get variables from previous step
          image_tag="${{ steps.build_container.outputs.image_tag }}"
          dockerfile_name="${{ steps.build_container.outputs.dockerfile_name }}"
          version="${{ needs.PREPARE-job.outputs.version }}"
          
          # Define output file
          output_file="${dockerfile_name}_${version}.tar"
          
          echo "Saving container to OCI archive..."
          echo "Image: $image_tag"
          echo "Output: $output_file"
          
          # Save with podman using OCI archive format
          podman save --format oci-archive "$image_tag" -o "$output_file"
          
          # Verify the file was created
          if [ -f "$output_file" ]; then
            file_size=$(ls -lh "$output_file" | awk '{print $5}')
            echo "✓ Archive saved successfully: $output_file (Size: $file_size)"
          else
            echo "✗ Failed to save archive: $output_file"
            exit 1
          fi
          
          # Set outputs
          # Output Variables:
          # - archive_file: Archive filename only (e.g., "ex1_0.0.5.tar")
          # - archive_path: Full path to archive (e.g., "/home/runner/work/repo/ex1_0.0.5.tar")
          # Usage in next steps: ${{ steps.save_container.outputs.archive_file }}
          echo "archive_file=$output_file" >> $GITHUB_OUTPUT
          echo "archive_path=${PWD}/$output_file" >> $GITHUB_OUTPUT

      - name: Copy to persistent local storage
        id: persistent_storage
        run: |
          # Get variables
          archive_file="${{ steps.save_container.outputs.archive_file }}"
          dockerfile_name="${{ steps.build_container.outputs.dockerfile_name }}"
          version="${{ needs.PREPARE-job.outputs.version }}"
          
          # Define persistent storage directory
          PERSISTENT_DIR="/container/${USER}/artifacts"
          echo "Setting up persistent storage at: $PERSISTENT_DIR"
          
          # Create directory if it doesn't exist
          mkdir -p "$PERSISTENT_DIR"
          
          # Copy archive to persistent storage with timestamp
          timestamp=$(date +"%Y%m%d_%H%M%S")
          persistent_filename="${dockerfile_name}_${version}_${timestamp}.tar"
          persistent_path="$PERSISTENT_DIR/$persistent_filename"
          
          echo "Copying archive to persistent storage..."
          echo "Source: $archive_file"
          echo "Destination: $persistent_path"
          
          if cp "$archive_file" "$persistent_path"; then
            # Verify the copy
            if [ -f "$persistent_path" ]; then
              file_size=$(ls -lh "$persistent_path" | awk '{print $5}')
              echo "✓ Archive successfully copied to persistent storage"
              echo "  [LOCATION]: $persistent_path"
              echo "  [SIZE]: $file_size"
              echo "  [TIMESTAMP]: $timestamp"
              
              # Also create a symlink to latest version (without timestamp)
              latest_link="$PERSISTENT_DIR/${dockerfile_name}_latest.tar"
              ln -sf "$persistent_filename" "$latest_link"
              echo "  [LATEST LINK]: $latest_link"
              
              # List all archives for this dockerfile
              echo "  [ALL VERSIONS]:"
              ls -la "$PERSISTENT_DIR/${dockerfile_name}_"*.tar 2>/dev/null || echo "    (No previous versions found)"
              
            else
              echo "✗ Archive copy verification failed"
              exit 1
            fi
          else
            echo "✗ Failed to copy archive to persistent storage"
            exit 1
          fi
          
          # Set outputs
          echo "persistent_path=$persistent_path" >> $GITHUB_OUTPUT
          echo "persistent_dir=$PERSISTENT_DIR" >> $GITHUB_OUTPUT
          echo "latest_link=$latest_link" >> $GITHUB_OUTPUT


      
  # BUILD-job:
  #   needs: PREPARE-job
  #   runs-on: ${{ needs.PREPARE-job.outputs.runner_label }}
  #   if: needs.PREPARE-job.outputs.proceed_valid == 'true'
  #   steps:
  #     - name: Print hostname
  #       run: |
  #         echo "Hostname: $(hostname)"
      
  #     - name: Checkout repository
  #       uses: actions/checkout@v4
  #       with:
  #         fetch-depth: 1  # As the runs-on machine maybe different from Build, re-checkout source code. Only the current commit is needed

  #     - name: Set up QEMU
  #       uses: docker/setup-qemu-action@v3
  #       with:
  #         platforms: ${{ needs.PREPARE-job.outputs.platform }}

  #     - name: Set up Docker Buildx
  #       uses: docker/setup-buildx-action@v3
  #       with:
  #         driver: docker-container
  #         install: true
    
  #     - name: Show current Buildx builders
  #       run: docker buildx ls

  #     - name: Enable BuildKit
  #       run: |
  #         echo ${{ needs.PREPARE-job.outputs.runner_label}} 
  #         echo "DOCKER_BUILDKIT=1" >> $GITHUB_ENV 

  #     - name: Check and set docker cache location
  #       id: docker_cache_check
  #       run: |
  #         CACHE_DIR="$HOME/runner/docker-cache"
  #         echo "CACHE_DIR=$CACHE_DIR"

  #         if [ -d "$CACHE_DIR" ]; then
  #           echo "Cache directory exists."
  #           CACHE_SIZE=$(du -sh "$CACHE_DIR" | cut -f1)
  #           echo "Cache directory size: $CACHE_SIZE"
  #         else
  #           echo "Cache directory does not exist. Creating..."
  #           if sudo mkdir -p "$CACHE_DIR"; then
  #             sudo chown $(whoami):$(id -gn) "$CACHE_DIR"
  #             echo "Cache directory created successfully."
  #           else
  #             echo "Failed to create cache directory: $CACHE_DIR" >&2
  #             exit 1
  #           fi
  #         fi

  #         echo "HOME=$HOME"
  #         echo "CACHELOC=$CACHE_DIR" >> $GITHUB_ENV
  #         echo "CACHELOC is set to ${CACHE_DIR} ".           

  #     - name: Build Docker image locally, save to tar file and move to persistent storage
  #       uses: docker/build-push-action@v6
  #       if: needs.PREPARE-job.outputs.devmode != 'true'
  #       with:
  #         context: ${{ github.workspace }}/${{ needs.PREPARE-job.outputs.directory }}
  #         file: ${{ github.workspace }}/${{ needs.PREPARE-job.outputs.files }}
  #         tags: | 
  #           ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}
  #         platforms: ${{ needs.PREPARE-job.outputs.platform }}
  #         push: false
  #         load: true
  #         provenance: false
  #         cache-from: type=local,src=${{env.CACHELOC}}
  #         cache-to: type=local,dest=${{env.CACHELOC}},mode=max
  #         # cache-from: type=gha
  #         # cache-to: type=gha,mode=max

  #     - name: Build Docker image locally, for development mode
  #       env:
  #         CACHELOC: ${{ env.CACHELOC }}
  #       if: needs.PREPARE-job.outputs.devmode == 'true'
  #       run: |
  #         docker buildx build \
  #           --progress plain \
  #           --cache-from type=local,src=${CACHELOC} \
  #           --cache-to type=local,dest=${CACHELOC},mode=max \
  #           --provenance=false \
  #           --load \
  #           --platform ${{ needs.PREPARE-job.outputs.platform }} \
  #           --file ${{ github.workspace }}/${{ needs.PREPARE-job.outputs.files }} \
  #           --tag ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} \
  #           ${{ github.workspace }}/${{ needs.PREPARE-job.outputs.directory }}

  #     - name: Save Docker image to tar file
  #       run: |
  #         docker save -o ${GITHUB_WORKSPACE}/image.tar ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}
  #         echo "Docker image saved to ${GITHUB_WORKSPACE}/image.tar"

  #     - name: Move image.tar to local persistent storage "$HOME/runner/artifacts"
  #       run: |
  #         sudo mkdir -p $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}
  #         sudo chown -R $(whoami):$(id -gn) $HOME/runner/artifacts/
  #         cp ${GITHUB_WORKSPACE}/image.tar $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar
  #         echo "Moved image.tar to $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar"


  # SCAN-AND-REPORT-job:
  #   needs: [BUILD-job, PREPARE-job]
  #   runs-on: ${{ needs.PREPARE-job.outputs.runner_label }}
  #   if: needs.PREPARE-job.outputs.proceed_valid == 'true' && needs.PREPARE-job.outputs.noscan != 'true'
  #   steps:
  #     - name: Print hostname
  #       run: |
  #         echo "Hostname: $(hostname)"
  #     - name: Copy back persistent storage "$HOME/runner/artifacts" to current directory 
  #       run: |
  #         if [ -f "$HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar" ]; then
  #           echo "File already exists, skipping copy."
  #         else
  #           cp $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar ${GITHUB_WORKSPACE}
  #           echo "Copied image.tar from $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar to ${GITHUB_WORKSPACE}"
  #         fi
  #     - name: Create Trivy report directory
  #       run: mkdir -p ./trivy-reports
  
  #     - name: Scan the Docker image with Trivy
  #       uses: aquasecurity/trivy-action@master
  #       with:
  #         input: './image.tar'        
  #         format: 'table'
  #         output: './trivy-reports/trivy-report-${{ needs.PREPARE-job.outputs.dockerfile_name }}.txt'
  #         severity: 'MEDIUM,CRITICAL,HIGH'
      
  #     - name: Add Trivy report to GitHub Actions summary
  #       run: |
  #         echo '## Trivy Scan Report for ${{ needs.PREPARE-job.outputs.dockerfile_name }}' >> $GITHUB_STEP_SUMMARY
  #         cat ./trivy-reports/trivy-report-${{ needs.PREPARE-job.outputs.dockerfile_name }}.txt >> $GITHUB_STEP_SUMMARY

  #     - name: Upload Trivy scan report
  #       uses: actions/upload-artifact@v4
  #       with:
  #           name: trivy-report-${{ needs.PREPARE-job.outputs.dockerfile_name }}
  #           path: ${{ github.workspace }}/trivy-reports/trivy-report-${{ needs.PREPARE-job.outputs.dockerfile_name}}.txt

  # PUSH-PRIV-job:
  #   needs: [BUILD-job, PREPARE-job]
  #   runs-on: ${{ needs.PREPARE-job.outputs.runner_label }}
  #   if: needs.PREPARE-job.outputs.proceed_valid == 'true'
  #   env:
  #    BUCKET: ${{ vars.ACACIA_BUCKETNAME }} # BYO or pawsey0001-image-compilation if compile for project
  #    DESTINATION_PATH: ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/${{ needs.PREPARE-job.outputs.date }}
  #   steps:
  #     - name: Print hostname and set approved label for deployment
  #       id: set_approved_label
  #       run: |
  #         echo "Hostname: $(hostname)"

  #     - name: Copy back persistent storage "$HOME/runner/artifacts" to current directory in case of running before scan
  #       run: |
  #         if [ -f "$HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar" ]; then
  #           echo "File already exists, skipping copy."
  #         else
  #           cp $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar ${GITHUB_WORKSPACE}
  #           echo "Copied image.tar from $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar to ${GITHUB_WORKSPACE}"
  #         fi

  #     - name: Setup rclone
  #       uses: ./.github/actions/setup-rclone
  #       with:
  #         access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
  #         secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
  #         endpoint: https://projects.pawsey.org.au
  #         bucket: ${{ env.BUCKET }}
  #         destination_path: ${{ env.DESTINATION_PATH }}

  #     - name: Upload image tar to S3 with rclone
  #       run: |
  #         set -e
      
  #         # calculate file size
  #         FILE_SIZE=$(wc -c < "${{ github.workspace }}/image.tar")
  #         echo "File size: $FILE_SIZE bytes"
      
  #         # dynamically set rclone parameters based on file size: 500MB, 5G,others
  #         if [ "$FILE_SIZE" -lt $((1024 * 1024 * 500)) ]; then
  #           S3_CHUNK_SIZE="16M"
  #           S3_UPLOAD_CONCURRENCY=4
  #           MULTI_THREAD_STREAMS=2
  #         elif [ "$FILE_SIZE" -lt $((1024 * 1024 * 5000)) ]; then
  #           S3_CHUNK_SIZE="64M"
  #           S3_UPLOAD_CONCURRENCY=8
  #           MULTI_THREAD_STREAMS=4
  #         else
  #           S3_CHUNK_SIZE="128M"
  #           S3_UPLOAD_CONCURRENCY=16
  #           MULTI_THREAD_STREAMS=8
  #         fi
    
      
  #         echo "Using S3 chunk size: $S3_CHUNK_SIZE"
  #         echo "Using S3 upload concurrency: $S3_UPLOAD_CONCURRENCY"
  #         echo "Using multi-thread streams: $MULTI_THREAD_STREAMS"

      
  #         # execute rclone copy
  #         rclone copy ${{ github.workspace }}/image.tar pawsey0001:"${{ env.BUCKET }}/${{ env.DESTINATION_PATH }}/" \
  #           --multi-thread-streams=$MULTI_THREAD_STREAMS \
  #           --s3-chunk-size=$S3_CHUNK_SIZE \
  #           --s3-upload-concurrency=$S3_UPLOAD_CONCURRENCY

  #     - name: Login to Docker Hub       
  #       uses: docker/login-action@v3
  #       with:
  #         username: ${{ vars.DOCKERHUB_USERNAME }}
  #         password: ${{ secrets.DOCKERHUB_TOKEN }}
      
  #     - name: Load Docker image from image.tar
  #       run: |
  #           docker load -i ${GITHUB_WORKSPACE}/image.tar

  #     - name: Tag Docker image for Dockerhub and Quay.IO
  #       run: |
  #         docker tag ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} ${{ vars.DOCKERHUB_USERNAME }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}

  #     - name: Push Docker image to Dockerhub after approval
  #       run: |          
  #         docker push ${{ vars.DOCKERHUB_USERNAME }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}

  #     - name: Remove Docker images
  #       run: |
  #         # Remove the main image
  #         docker rmi ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} || true
        
  #           # Remove tagged images
  #         docker rmi ${{ vars.DOCKERHUB_USERNAME }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} || true


  # CLEANUP-job:
  #   needs: [APPROVE-PUSH-PUB-job,PUSH-PRIV-job, SCAN-AND-REPORT-job, BUILD-job, PREPARE-job]
  #   if: always()
  #   runs-on: ${{ needs.PREPARE-job.outputs.runner_label }}
  #   steps:
  #     - name: Clean-up
  #       run: |
  #         sudo rm -rf $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}

  # DEPLOY-job:
  #   needs: [PUSH-PRIV-job,PREPARE-job]
  #   runs-on: Ella
  #   if: needs.PREPARE-job.outputs.platform_tag == 'arm'
  #   env:
  #     BUCKET: ${{ vars.ACACIA_BUCKETNAME }} # BYO or pawsey0001-image-compilation if compile for project
  #     DESTINATION_PATH: ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/${{ needs.PREPARE-job.outputs.date }}
  #   #environment:
  #    # name: manual_approval  
  #   steps:
  #     - name: Checkout repository
  #       uses: actions/checkout@v4
  #       with:
  #         fetch-depth: 1  # As the runs-on machine maybe different from Build, re-checkout source code. Only the current commit is needed

  #     - name: Setup rclone
  #       uses: ./.github/actions/setup-rclone
  #       with:
  #         access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
  #         secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
  #         endpoint: https://projects.pawsey.org.au
  #         bucket: ${{ env.BUCKET }}
  #         destination_path: ${{ env.DESTINATION_PATH }}
  #     - name: Deploy ARM image to Ella  
  #       run: |
  #           echo "Deploying ARM image to Ella"
  #           echo "Hostname: $(hostname)"
  #           echo "Deploying image: ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}" to Ella
  #           mkdir -p $MYSCRATCH/image/${{ needs.PREPARE-job.outputs.dockerfile_name }}/
  #           rclone copy pawsey0001:"${{ env.BUCKET }}/${{ env.DESTINATION_PATH }}/image.tar" $MYSCRATCH/image/${{ needs.PREPARE-job.outputs.dockerfile_name }}/
  #     - name: Convert to Singularity File
  #       run: |
  #           echo "Converting to Singularity File"
  #           echo "Converting image: ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}" to Singularity
  #           source ~/.bashrc
          
  #           singularity build --force $MYSCRATCH/image/${{ needs.PREPARE-job.outputs.dockerfile_name }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}.sif docker-archive://$MYSCRATCH/image/${{ needs.PREPARE-job.outputs.dockerfile_name }}/image.tar
  
  # APPROVE-PUSH-PUB-job:
  #   needs: [BUILD-job, PREPARE-job]
  #   runs-on: ${{ needs.PREPARE-job.outputs.runner_label }}
  #   if: needs.PREPARE-job.outputs.proceed_valid == 'true'
  #   environment:
  #     name: manual_approval  
  #   steps:
  #     - name: Print hostname and set approved label for deployment
  #       id: set_approved_label
  #       run: |
  #         echo "Hostname: $(hostname)"
  #     - name: Copy back persistent storage "$HOME/runner/artifacts" to current directory in case of running before scan
  #       run: |
  #         if [ -f "$HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar" ]; then
  #           echo "File already exists, skipping copy."
  #         else
  #           cp $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar ${GITHUB_WORKSPACE}
  #           echo "Copied image.tar from $HOME/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar to ${GITHUB_WORKSPACE}"
  #         fi

  #     - name: Login to quay Container Registry
  #       uses: docker/login-action@v3
  #       with:
  #         registry: quay.io
  #         username: ${{ vars.QUAYIO_USERNAME }}
  #         password: ${{ secrets.QUAYIO_TOKEN }}
      
  #     - name: Load Docker image from image.tar
  #       run: |
  #           docker load -i ${GITHUB_WORKSPACE}/image.tar

  #     - name: Tag Docker image for Dockerhub and Quay.IO
  #       run: |
  #         docker tag ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} quay.io/${{ vars.QUAYIO_USERNAME }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}
  #         docker tag ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} quay.io/pawsey/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}

  #     - name: Push Docker image to Quay.IO after approval
  #       if: needs.PREPARE-job.outputs.devmode != 'true'
  #       run: |          
  #         docker push quay.io/${{ vars.QUAYIO_USERNAME }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}
  #         docker push quay.io/pawsey/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}

  #     - name: Remove Docker images
  #       run: |
  #         # Remove the main image
  #         docker rmi ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} || true
        
  #           # Remove tagged images
  #         docker rmi quay.io/${{ vars.QUAYIO_USERNAME }}/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} || true 
  #         docker rmi quay.io/pawsey/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} || true       
         




  # APPROVE-AND-DEPLOY-job:
  #   needs: [SCAN-AND-REPORT-job, PREPARE-job]
  #   runs-on: experiment
  #   if: needs.PREPARE-job.outputs.proceed_valid == 'true'
  #   strategy:
  #     matrix:
  #       task: [push-dockerhub, push-quay, upload-s3]
  #   env:
  #     BUCKET: pawsey0001-image-compilation
  #     DESTINATION_PATH: ${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}
  #   environment:
  #     name: manual_approval  
  #   steps:
  #     - name: Copy back persistent storage "/home/runner/artifacts" to current directory
  #       run: |
  #         cp /home/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar ${GITHUB_WORKSPACE}
  #         echo "Copied image.tar from /home/runner/artifacts/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}/image.tar to ${GITHUB_WORKSPACE}"
      
  #     - name: Load Docker image from image.tar and tag for dockerhub and quay.io
  #       run: |
  #         docker load -i ${GITHUB_WORKSPACE}/image.tar
  #         docker tag klinus/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }} quay.io/klinus/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}

  #     - name: Login to Docker Hub
  #       if: matrix.task == 'push-dockerhub'
  #       uses: docker/login-action@v3
  #       with:
  #         username: ${{ vars.DOCKERHUB_USERNAME }}
  #         password: ${{ secrets.DOCKERHUB_TOKEN }}        

  #     - name: Push Docker image to DockerHub
  #       if: matrix.task == 'push-dockerhub'
  #       run: |
  #         docker push klinus/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}
      
  #     - name: Login to Quay Container Registry
  #       if: matrix.task == 'push-quay'
  #       uses: docker/login-action@v3
  #       with:
  #         registry: quay.io
  #         username: ${{ vars.QUAYIO_USERNAME }}
  #         password: ${{ secrets.QUAYIO_TOKEN }}

  #     - name: Push Docker image to Quay.IO after approval
  #       if: matrix.task == 'push-quay'
  #       run: |
  #         docker push quay.io/klinus/${{ needs.PREPARE-job.outputs.dockerfile_name }}-${{ needs.PREPARE-job.outputs.platform_tag }}:${{ needs.PREPARE-job.outputs.date }}

  #     # Steps for uploading to S3 with rclone
  #     - name: Setup rclone
  #       if: matrix.task == 'upload-s3'
  #       uses: ./.github/actions/setup-rclone
  #       with:
  #         access_key_id: ${{ secrets.ACACIA_ACCESS_KEY_ID }}
  #         secret_access_key: ${{ secrets.ACACIA_SECRET_ACCESS_KEY }}
  #         endpoint: https://projects.pawsey.org.au
  #         bucket: ${{ env.BUCKET }}
  #         destination_path: ${{ env.DESTINATION_PATH }}
      
  #     - name: Upload image tar to S3 with rclone
  #       if: matrix.task == 'upload-s3'
  #       run: |
  #         set -e
  #         rclone copy ${{ github.workspace }}/image.tar pawsey0001:"${{ env.BUCKET }}/${{ env.DESTINATION_PATH }}/"